-- Add questions 11-40 to the database
INSERT INTO questions (question_text, choice_a, choice_b, choice_c, choice_d, correct_answer, explanation, category_id) VALUES
('Your marketing department wants to send out a promotional email campaign. The development team wants to minimize direct operation management. They project a wide range of possible customer responses, from 100 to 500,000 click-through per day. The link leads to a simple website that explains the promotion and collects user information and preferences. Which infrastructure should you recommend? (Choose two.)', 'Use Google App Engine to serve the website and Google Cloud Datastore to store user data.', 'Use a Google Container Engine cluster to serve the website and store data to persistent disk.', 'Use a managed instance group to serve the website and Google Cloud Bigtable to store user data.', 'Use a single Compute Engine virtual machine (VM) to host a web server, backend by Google Cloud SQL.', 'AC', 'Correct Answer: AC. Reference: https://cloud.google.com/storage-options/'),

('Your company just finished a rapid lift and shift to Google Compute Engine for your compute needs. You have another 9 months to design and deploy a more cloud-native solution. Specifically, you want a system that is no-ops and auto-scaling. Which two compute products should you choose? (Choose two.)', 'Compute Engine with containers', 'Google Kubernetes Engine with containers', 'Google App Engine Standard Environment', 'Compute Engine with custom instance types', 'BC', 'Correct Answer: BC. B: With Container Engine, Google will automatically deploy your cluster for you, update, patch, secure the nodes. Kubernetes Engine''s cluster autoscaler automatically resizes clusters based on the demands of the workloads you want to run. C: Solutions like Datastore, BigQuery, AppEngine, etc are truly NoOps. App Engine by default scales the number of instances running up and down to match the load, thus providing consistent performance for your app at all times while minimizing idle instances and thus reducing cost.'),

('One of your primary business objectives is being able to trust the data stored in your application. You want to log all changes to the application data. How can you design your logging system to verify authenticity of your logs?', 'Write the log concurrently in the cloud and on premises', 'Use a SQL database and limit who can modify the log table', 'Digitally sign each timestamp and log entry and store the signature', 'Create a JSON dump of each log entry and store it in Google Cloud Storage', 'C', 'Correct Answer: C. Digitally sign each timestamp and log entry and store the signature. Answer A, B, and D don''t have any added value to verify the authenticity of your logs. To verify the authenticity of your logs if they are tampered with or forged, you can use a certain algorithm to generate digest by hashing each timestamp or log entry and then digitally sign the digest with a private key to generate a signature.'),

('Your company has decided to make a major revision of their API in order to create better experiences for their developers. They need to keep the old version of the API available and deployable, while allowing new customers and testers to try out the new API. They want to keep the same SSL and DNS records in place to serve both APIs. What should they do?', 'Configure a new load balancer for the new version of the API', 'Reconfigure old clients to use a new endpoint for the new API', 'Have the old API forward traffic to the new API based on the path', 'Use separate backend pools for each API path behind the load balancer', 'D', 'Correct Answer: D. HTTP(S) load balancer can direct traffic reaching a single IP to different backends based on the incoming URL. A is not correct because configuring a new load balancer would require a new or different SSL and DNS records which conflicts with the requirements.'),

('Your company plans to migrate a multi-petabyte data set to the cloud. The data set must be available 24hrs a day. Your business analysts have experience only with using a SQL interface. How should you store the data to optimize it for ease of analysis?', 'Load data into Google BigQuery', 'Insert data into Google Cloud SQL', 'Put flat files into Google Cloud Storage', 'Stream data into Google Cloud Datastore', 'A', 'Correct Answer: A. BigQuery is Google''s serverless, highly scalable, low cost enterprise data warehouse designed to make all your data analysts productive. Because there is no infrastructure to manage, you can focus on analyzing data to find meaningful insights using familiar SQL and you don''t need a database administrator. B isn''t correct because Cloud SQL does not scale to that volume.'),

('The operations manager asks you for a list of recommended practices that she should consider when migrating a J2EE application to the cloud. Which three practices should you recommend? (Choose three.)', 'Port the application code to run on Google App Engine', 'Integrate Cloud Dataflow into the application to capture real-time metrics', 'Instrument the application with a monitoring tool like Stackdriver Debugger', 'Select an automation framework to reliably provision the cloud infrastructure', 'ADE', 'Correct Answer: ADE. A: Appengine cloud native server less platform. D: Automation framework like Terraform can be used. E: Use CI/CD tools as a best practice.'),

('A news feed web service has the following code running on Google App Engine. During peak load, users report that they can see news articles they already viewed. What is the most likely cause of this problem?', 'The session variable is local to just a single instance', 'The session variable is being overwritten in Cloud Datastore', 'The URL of the API needs to be modified to prevent caching', 'The HTTP Expires header needs to be set to -1 stop caching', 'A', 'Correct Answer: A. C, D is rule out, because of this statement "During peak load, users report that they can see news articles they already viewed". C & D got nothing to with peak load. The session variable is local to just a single instance, so during peak load when multiple instances are running, users might be routed to different instances.'),

('An application development team believes their current logging tool will not meet their needs for their new cloud-based product. They want a better tool to capture errors and help them analyze their historical log data. You want to help them find a solution that meets their needs. What should you do?', 'Direct them to download and install the Google StackDriver logging agent', 'Send them a list of online resources about logging best practices', 'Help them define their requirements and assess viable logging tools', 'Help them upgrade their current tool to take advantage of any new features', 'C', 'Correct Answer: C. Even though this is gcp exam. They check real architect skill over gcp product. Since team needs only suggestion answer C is correct.'),

('You need to reduce the number of unplanned rollbacks of erroneous production deployments in your company''s web hosting platform. Improvement to the QA/Test processes accomplished an 80% reduction. Which additional two approaches can you take to further reduce the rollbacks? (Choose two.)', 'Introduce a green-blue deployment model', 'Replace the QA environment with canary releases', 'Fragment the monolithic platform into microservices', 'Reduce the platform''s dependency on relational database systems', 'AC', 'Correct Answer: AC. QA reduced the number of issues so it is not convenient to get rid of them, therefore B is not correct. Any of the application deployments and testing strategies will be valid, although Roll updates has slow rollbacks. Microservices is the key in terms of the reducing rollbacks, not the deployment strategies.'),

('To reduce costs, the Director of Engineering has required all developers to move their development infrastructure resources from on-premises virtual machines (VMs) to Google Cloud Platform. These resources go through multiple start/stop events during the day and require state to persist. You have been asked to design the process of running a development environment in Google Cloud while providing cost visibility to the finance department. Which two steps should you take? (Choose two.)', 'Use the --no-auto-delete flag on all persistent disks and stop the VM', 'Use the --auto-delete flag on all persistent disks and terminate the VM', 'Apply VM CPU utilization label and include it in the BigQuery billing export', 'Use Google BigQuery billing export and labels to associate cost to groups', 'AD', 'Correct Answer: AD. State is lost when Compute Engine is stopped. Auto-delete has impact only when the VM is deleted (it does not apply when VM is stopped). Use BigQuery billing export and labels to associate cost to groups for cost visibility.'),

('Your company wants to track whether someone is present in a meeting room reserved for a scheduled meeting. There are 1000 meeting rooms across 5 offices on 3 continents. Each room is equipped with a motion sensor that reports its status every second. The data from the motion detector includes only a sensor ID and several different discrete items of information. Analysts will use this data, together with information about account owners and office locations. Which database type should you use?', 'Flat file', 'NoSQL', 'Relational', 'Blobstore', 'B', 'Correct Answer: B. Relational databases were not designed to cope with the scale and agility challenges that face modern applications, nor were they built to take advantage of the commodity storage and processing power available today. NoSQL fits well for: Developers are working with applications that create massive volumes of new, rapidly changing data types — structured, semi-structured, unstructured and polymorphic data.'),

('You set up an autoscaling instance group to serve web traffic for an upcoming launch. After configuring the instance group as a backend service to an HTTP(S) load balancer, you notice that virtual machine (VM) instances are being terminated and re-launched every minute. The instances do not have a public IP address. You have verified the appropriate web response is coming from each instance using the curl command. You want to ensure the backend is configured correctly. What should you do?', 'Ensure that a firewall rules exists to allow source traffic on HTTP/HTTPS to reach the load balancer.', 'Assign a public IP to each instance and configure a firewall rule to allow the load balancer to reach the instance public IP.', 'Ensure that a firewall rule exists to allow load balancer health checks to reach the instances in the instance group.', 'Create a tag on each instance with the name of the load balancer. Configure a firewall rule with the name of the load balancer as the source and the instance tag as the destination.', 'C', 'Correct Answer: C. A and B wouldn''t turn the VMs on or off, it would just prevent traffic. C would turn them off if the health check is configured to terminate the VM is it fails. The best practice when configuration a health check is to check health and serve traffic on the same port.'),

('You write a Python script to connect to Google BigQuery from a Google Compute Engine virtual machine. The script is printing errors that it cannot connect to BigQuery. What should you do to fix the script?', 'Install the latest BigQuery API client library for Python', 'Run your script on a new virtual machine with the BigQuery access scope enabled', 'Create a new service account with BigQuery access and execute your script with that user', 'Install the bq component for gcloud with the command gcloud components install bq.', 'B', 'Correct Answer: B. Giving the service account permissions does no good if the GCE instance itself is blocked: "You must set access scopes on the instance to authorize access. While a service account''s access level is determined by the IAM roles granted to the service account, an instance''s access scopes determine the default OAuth scopes for requests made through the gcloud tool and client libraries on the instance."'),

('Your customer is moving an existing corporate application to Google Cloud Platform from an on-premises data center. The business owners require minimal user disruption. There are strict security team requirements for storing passwords. What authentication strategy should they use?', 'Use G Suite Password Sync to replicate passwords into Google', 'Federate authentication via SAML 2.0 to the existing Identity Provider', 'Provision users in Google using the Google Cloud Directory Sync tool', 'Ask users to set their Google password to match their corporate password', 'B', 'Correct Answer: B. Federate authentication via SAML 2.0 to the existing Identity Provider. This doesn''t require password synchronization and provides minimal user disruption while maintaining security requirements.'),

('Your company has successfully migrated to the cloud and wants to analyze their data stream to optimize operations. They do not have any existing code for this analysis, so they are exploring all their options. These options include a mix of batch and stream processing, as they are running some hourly jobs and live-processing some data as it comes in. Which technology should they use for this?', 'Google Cloud Dataproc', 'Google Cloud Dataflow', 'Google Container Engine with Bigtable', 'Google Compute Engine with Google BigQuery', 'B', 'Correct Answer: B. Cloud Dataflow is a fully-managed service for transforming and enriching data in stream (real time) and batch (historical) modes with equal reliability and expressiveness -- no more complex workarounds or compromises needed.'),

('Your customer is receiving reports that their recently updated Google App Engine application is taking approximately 30 seconds to load for some of their users. This behavior was not reported before the update. What strategy should you take?', 'Work with your ISP to diagnose the problem', 'Open a support ticket to ask for network capture and flow data to diagnose the problem, then roll back your application', 'Roll back to an earlier known good release initially, then use Stackdriver Trace and Logging to diagnose the problem in a development/test/staging environment', 'Roll back to an earlier known good release, then push the release again at a quieter period to investigate. Then use Stackdriver Trace and Logging to diagnose the problem', 'C', 'Correct Answer: C. C seems a reasonable first approach as it gets production back quickly and takes advantage of the ability to provision a cloud staging environment immediately. Stackdriver Logging allows you to store, search, analyze, monitor, and alert on log data and events.'),

('A production database virtual machine on Google Compute Engine has an ext4-formatted persistent disk for data files. The database is about to run out of storage space. How can you remediate the problem with the least amount of downtime?', 'In the Cloud Platform Console, increase the size of the persistent disk and use the resize2fs command in Linux.', 'Shut down the virtual machine, use the Cloud Platform Console to increase the persistent disk size, then restart the virtual machine', 'In the Cloud Platform Console, increase the size of the persistent disk and verify the new space is ready to use with the fdisk command in Linux', 'In the Cloud Platform Console, create a new persistent disk attached to the virtual machine, format and mount it, and configure the database service to move the files to the new disk', 'A', 'Correct Answer: A. On Linux instances, connect to your instance and manually resize your partitions and file systems to use the additional disk space that you added. Extend the file system on the disk or the partition to use the added space with resize2fs command.'),

('Your application needs to process credit card transactions. You want the smallest scope of Payment Card Industry (PCI) compliance without compromising the ability to analyze transactional data and trends relating to which payment methods are used. How should you design your architecture?', 'Create a tokenizer service and store only tokenized data', 'Create separate projects that only process credit card data', 'Create separate subnetworks and isolate the components that process credit card data', 'Streamline the audit discovery phase by labeling all of the virtual machines (VMs) that process PCI data', 'A', 'Correct Answer: A. Tokenization (for example with Cloud DLP) do not disturb analysis. Most of them opt for A or E. IMO difference between A and E is that A "hides" (tokenizes) the PII data itself whereas E does not allow the auditors to VIEW the PII data. Nowhere in the question is about AUDITING. The question is about ANALYSIS.'),

('You have been asked to select the storage system for the click-data of your company''s large portfolio of websites. This data is streamed in from a custom website analytics package at a typical rate of 6,000 clicks per minute. With bursts of up to 8,500 clicks per second. It must have been stored for future analysis by your data science and user experience teams. Which storage infrastructure should you choose?', 'Google Cloud SQL', 'Google Cloud Bigtable', 'Google Cloud Storage', 'Google Cloud Datastore', 'B', 'Correct Answer: B. Google Cloud Bigtable is a scalable, fully-managed NoSQL wide-column database that is suitable for both real-time access and analytics workloads. Good for: Low-latency read/write access, High-throughput analytics, Native time series support. Common workloads: IoT, finance, adtech, Personalization, recommendations, Monitoring, Geospatial datasets, Graphs.'),

('You are creating a solution to remove backup files older than 90 days from your backup Cloud Storage bucket. You want to optimize ongoing Cloud Storage spend. What should you do?', 'Write a lifecycle management rule in XML and push it to the bucket with gsutil', 'Write a lifecycle management rule in JSON and push it to the bucket with gsutil', 'Schedule a cron script using gsutil ls —lr gs://backups/** to find and remove items older than 90 days', 'Schedule a cron script using gsutil ls —l gs://backups/** to find and remove items older than 90 days and schedule it with cron', 'B', 'Correct Answer: B. gsutil command takes only json as input for lifecycle management. JSON is slightly faster than XML because of the "{" verse "<c>" distinguisher, with a Trie tree used for alphanumeric parsing.'),

('Your company is forecasting a sharp increase in the number and size of Apache Spark and Hadoop jobs being run on your local datacenter. You want to utilize the cloud to help you scale this upcoming demand with the least amount of operations work and code change. Which product should you use?', 'Google Cloud Dataflow', 'Google Cloud Dataproc', 'Google Compute Engine', 'Google Kubernetes Engine', 'B', 'Correct Answer: B. Google Cloud Dataproc is a fast, easy-to-use, low-cost and fully managed service that lets you run the Apache Spark and Apache Hadoop ecosystem on Google Cloud Platform. Cloud Dataproc provisions big or small clusters rapidly, supports many popular job types, and is integrated with other Google Cloud Platform services.'),

('The database administration team has asked you to help them improve the performance of their new database server running on Google Compute Engine. The database is for importing and normalizing their performance statistics and is built with MySQL running on Debian Linux. They have an n1-standard-8 virtual machine with 80 GB of SSD persistent disk. What should they change to get better performance from this system?', 'Increase the virtual machine''s memory to 64 GB', 'Create a new virtual machine running PostgreSQL', 'Dynamically resize the SSD persistent disk to 500 GB', 'Migrate their performance metrics warehouse to BigQuery', 'C', 'Correct Answer: C. Answer is C because persistent disk performance is based on the total persistent disk capacity attached to an instance and the number of vCPUs that the instance has. Incrementing the persistent disk capacity will increment its throughput and IOPS, which in turn improve the performance of MySQL.'),

('You want to optimize the performance of an accurate, real-time, weather-charting application. The data comes from 50,000 sensors sending 10 readings a second, in the format of a timestamp and sensor reading. Where should you store the data?', 'Google BigQuery', 'Google Cloud SQL', 'Google Cloud Bigtable', 'Google Cloud Storage', 'C', 'Correct Answer: C. Google Cloud Bigtable is a scalable, fully-managed NoSQL wide-column database that is suitable for both real-time access and analytics workloads. Good for: Low-latency read/write access, High-throughput analytics, Native time series support. Common workloads: IoT, finance, adtech, Personalization, recommendations, Monitoring, Geospatial datasets, Graphs.'),

('Your company''s user-feedback portal comprises a standard LAMP stack replicated across two zones. It is deployed in the us-central1 region and uses auto-scaled managed instance groups on all layers, except the database. Currently, only a small group of select customers have access to the portal. The portal meets a 99,99% availability SLA under these conditions. However next quarter, your company will be making the portal available to all users, including unauthenticated users. You need to develop a resiliency testing strategy to ensure the system maintains the SLA once they introduce additional user load. What should you do?', 'Capture existing users input, and replay captured user load until auto-scale is triggered on all layers. At the same time, terminate all resources in one of the zones', 'Create synthetic random user input, replay synthetic load until auto-scale logic is triggered on at least one layer, and introduce "chaos" to the system by terminating random resources on both zones', 'Expose the new system to a larger group of users, and increase group size each day until auto-scale logic is triggered on all layers. At the same time, terminate random resources on both zones', 'Capture existing users input, and replay captured user load until resource utilization crosses 80%. Also, derive estimated number of users based on existing user''s usage of the app, and deploy enough resources to handle 200% of expected load', 'B', 'Correct Answer: B. Resilience test is not about load, is about terminate resources and service not affected. Think it''s B. The best for resilience in to introduce chaos in the infrastructure.'),

('One of the developers on your team deployed their application in Google Container Engine with the Dockerfile below. They report that their application deployments are taking too long. You want to optimize this Dockerfile for faster deployment times without adversely affecting the app''s functionality. Which two actions should you take? (Choose two.)', 'Remove Python after running pip', 'Remove dependencies from requirements.txt', 'Use a slimmed-down base image like Alpine Linux', 'Use larger machine types for your Google Container Engine node pools', 'CE', 'Correct Answer: CE. C: Smaller the base image with minimum dependency faster the container will start. E: Docker image build uses caching. Docker Instructions sequence matter because application''s dependencies change less frequently than the Python code which will help to reuse the cached layer of dependency and only add new layer for code change for Python Source code.'),

('Your solution is producing performance bugs in production that you did not see in staging and test environments. You want to adjust your test and deployment procedures to avoid this problem in the future. What should you do?', 'Deploy fewer changes to production', 'Deploy smaller changes to production', 'Increase the load on your test and staging environments', 'Deploy changes to a small subset of users before rolling out to production', 'D', 'Correct Answer: D. D would allow you to test the new code against smaller user sets to see if it occurs then, and if it still does you know it is not because of more user responses. Canary test pattern In canary testing, you partially roll out a change and then evaluate its performance against a baseline deployment.'),

('A small number of API requests to your microservices-based application take a very long time. You know that each request to the API can traverse many services. You want to know which service takes the longest in those cases. What should you do?', 'Set timeouts on your application so that you can fail requests faster', 'Send custom metrics for each of your requests to Stackdriver Monitoring', 'Use Stackdriver Monitoring to look for insights that show when your API latencies are high', 'Instrument your application with Stackdriver Trace in order to break down the request latencies at each microservice', 'D', 'Correct Answer: D. D should be correct, the headline in GC trace documentation says it all: "Cloud Trace is a distributed tracing system for Google Cloud that collects latency data from applications and displays it in near real-time in the Google Cloud Console."'),

('During a high traffic portion of the day, one of your relational databases crashes, but the replica is never promoted to a master. You want to avoid this in the future. What should you do?', 'Use a different database', 'Choose larger instances for your database', 'Create snapshots of your database more regularly', 'Implement routinely scheduled failovers of your databases', 'B', 'Correct Answer: B. Overall you see the ''D'' is correct. However, look for the key words, during high volume only the problem situation happens. Why only during high volume? The possible cause then would be the size of the database. The ONLY possible cause for Cloud SQL to not promote a replica to master is when the instance is at 100%. The only way to fix it is to increase capacity.'),

('Your organization requires that metrics from all applications be retained for 5 years for future analysis in possible legal proceedings. Which approach should you use?', 'Grant the security team access to the logs in each Project', 'Configure Stackdriver Monitoring for all Projects, and export to BigQuery', 'Configure Stackdriver Monitoring for all Projects with the default retention policies', 'Configure Stackdriver Monitoring for all Projects, and export to Google Cloud Storage', 'B', 'Correct Answer: B. Best practice: Keep your data in BigQuery. When you load data into BigQuery from Cloud Storage, you are not charged for the load operation, but you do incur charges for storing the data in Cloud Storage. After the data is loaded into BigQuery, the data is subject to BigQuery''s storage pricing.'),

('Your company has decided to build a backup replica of their on-premises user authentication PostgreSQL database on Google Cloud Platform. The database is 4 TB, and large updates are frequent. Replication requires private address space communication. Which networking approach should you use?', 'Google Cloud Dedicated Interconnect', 'Google Cloud VPN connected to the data center network', 'A NAT and TLS translation gateway installed on-premises', 'A Google Compute Engine instance with a VPN server installed connected to the data center network', 'A', 'Correct Answer: A. Google Cloud Dedicated Interconnect provides direct physical connections and RFC 1918 communication between your on-premises network and Google''s network. Dedicated Interconnect enables you to transfer large amounts of data between networks, which can be more cost effective than purchasing additional bandwidth over the public Internet or using VPN tunnels.');